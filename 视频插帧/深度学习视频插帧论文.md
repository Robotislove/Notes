# 深度学习视频插帧论文

## 性能对比
工作需要，做了一些视频插帧的开源算法对比： 

对比数据集：UCF101: image size:256x256，image numbers: 379 

代码运行环境为阿里云 V100 16GB，主要考虑推理时间(ms)，性能指标及显存占用。ps:图中infer time是ms

![index](https://raw.githubusercontent.com/lhondong/PicGo/main/img/index.png)

1080p的的视频片段，共625帧，推理时间为整个程序的运行时间。 

![nethodl](https://raw.githubusercontent.com/lhondong/PicGo/main/img/nethodl.png)

[代码](https://github.com/zdyshine/Video-Frame-Interpolation-Summary)：只给出了推理代码，放到对应的源码中即可运行。

## Paper list:

1. DAIN (Depth-Aware Video Frame Interpolation) [paper](https://arxiv.org/pdf/1904.00830.pdf) [code](https://github.com/baowenbo/DAIN)  
   使用深度感知的流投影层来估计双向流加权组合的中间流。
2. EQVI (Enhanced Quadratic Video Interpolation)  [paper](https://arxiv.org/pdf/2009.04642.pdf) [code](https://github.com/lyh-18/EQVI)
3. RIFE v2.4 - Real Time Video Interpolation  [paper](https://arxiv.org/pdf/2011.06294.pdf) [code](https://github.com/hzwer/arXiv2020-RIFE)
4. CAIN (Channel Attention Is All You Need for Video Frame Interpolation) [paper](https://aaai.org/ojs/index.php/AAAI/article/view/6693/6547) [code](https://github.com/myungsub/CAIN)   
   一种高效的无光流估计方法，使用PixelShuffle算子和channel attention来隐式捕捉运动信息。
5. FLAVR (Flow-Agnostic Video Representations for Fast Frame Interpolation) (不依赖光流) [paper](https://arxiv.org/pdf/2012.08512.pdf) [code](https://github.com/tarun005/FLAVR)
6. RRIN(Video Frame Interpolation via Residue Refinement) (不依赖光流) [paper](https://ieeexplore.ieee.org/document/9053987/) [code](https://github.com/HopLee6/RRIN)
7. AdaCoF (Adaptive Collaboration of Flows for Video Frame Interpolation) [paper](https://arxiv.org/pdf/1907.10244.pdf) [code](https://github.com/HyeongminLEE/AdaCoF-pytorch)
8.  CDFI (Compression-Driven Network Design for Frame Interpolation) [paper](https://arxiv.org/pdf/2103.10559.pdf) [code](https://github.com/tding1/CDFI)
9.  EDSC (Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution) [paper](https://arxiv.org/pdf/2006.08070.pdf) [code](https://github.com/Xianhang/EDSC-pytorch)  
    提出DSepConv[6]利用可变形可分卷积扩展基于核的方法，并进一步提出EDSC[5]执行多次插补。
10. UTI-VFI (Video Frame Interpolation without Temporal Priors) [paper](https://github.com/yjzhang96/UTI-VFI/raw/master/paper/nips_camera_ready.pdf) [code](https://github.com/yjzhang96/UTI-VFI)

## Dataset
UCF101: [Download](https://liuziwei7.github.io/projects/VoxelFlow)

Vimeo90K: [Download](https://toflow.csail.mit.edu/)

MiddleBury: [Download](https://vision.middlebury.edu/flow/data/)

HD: [Download](https://github.com/baowenbo/MEMC-Net)