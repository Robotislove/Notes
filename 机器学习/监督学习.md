# 机器学习

一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。

我认为经验E就是程序上万次的自我练习的经验而任务T就是下棋。性能度量值P呢，就是它在与一些新的对手比赛时，赢得比赛的概率。

[TOC]

# 监督学习

监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。

## 回归

试着推测出一个连续值的结果

### 单变量线性回归(Linear Regression with One Variable, Univariate linear regression)

$m$ 代表训练集中实例的数量

$x$ 代表特征/输入变量

$y$ 代表目标变量/输出变量

$(x,y)$ 代表训练集中的实例

$(x^{(i)},y^{(i)})$ 代表第 $i$ 个观察实例

$h$ 代表学习算法的解决方案或函数也称为假设（**hypothesis**）

$h_{\theta}(x) = \theta_0+\theta_1x$

接下来为我们的模型选择合适的**参数**（**parameters**）$\theta_0$和$\theta_1$

我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数

$J(\theta_0,\theta_1) = \frac{1}{2m}\sum\limits_{i = 1}^{m}(h_\theta(x^{(i)}) - y^{(i)})^2$

即 $\min \limits_{\theta_0,\theta_1}{J(\theta_0,\theta_1)}$

#### 代价函数（平方误差函数）

误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。

还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。

对于 $h_\theta(x)$,如果 $\theta_0,\theta_1$ 固定，$h_\theta(x)$ 是关于$x$的函数，而代价函数 $J(\theta_0,\theta_1)$ 是关于 $\theta_0,\theta_1$ 的函数。

#### 梯度下降

梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数 $J(\theta_0,\theta_1)$ 的最小值。

梯度下降背后的思想是：开始时我们随机选择一个参数的组合 $(\theta_0,\theta_1,...,\theta_n)$ ，计算代价函数，然后寻找下一个能让代价函数值下降最多的参数组合。持续这么做直到到到一个局部最小值（**local minimum** ），因为并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（**global minimum**），选择不同的初始参数组合，可能会找到不同的局部最小值。

<<<<<<< HEAD
$\theta_{j}:=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J\left(\theta_{0}, \theta_{1}\right) \quad$ (for $j=0$ and $****\left.j=1\right)$
=======
$\theta_{j}:=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J\left(\theta_{0}, \theta_{1}\right) \quad$ (for $j=0$ and $j=1)$
>>>>>>> 0e3eb5a (2021.11)

$\alpha$ 是学习率（**learning rate** ），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。在梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。

Simultaneous update，同时更新$\theta_0$和$\theta_1$。

$\theta_{0}:=\theta_{0}$，并更新 $\theta_{1}:=\theta_{1}$

实现方法是：你应该计算公式右边的部分，通过那一部分计算出$\theta_{0}$和$\theta_{1}$的值，然后同时更新$\theta_{0}$和$\theta_{1}$。

$temp0:=\theta_{0} - \alpha \frac{\partial}{\partial \theta_{0}} J(\theta_{0}, \theta_{1}) $

$temp1:=\theta_{1} - \alpha \frac{\partial}{\partial \theta_{1}} J(\theta_{0}, \theta_{1}) $

$\theta_{0}:=temp0$

$\theta_{1}:=temp1$

**学习率$\alpha$**

如果$\alpha$太小了，即学习速率太小，结果就是只能这样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果$\alpha$太小的话，可能会很慢，需要很多步才能到达全局最低点。

如果$\alpha$太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果$\alpha$太大，它会导致无法收敛，甚至发散。

即使学习速率$\alpha$保持不变时，梯度下降也可以收敛到局部最低点。在梯度下降法中，当接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当接近局部最低点时，很显然在局部最低时导数接近零，所以当接近局部最低时，导数值会自动变得越来越小，梯度下降将自动采取较小的幅度，实际上没有必要再另外减小$\alpha$。

$\frac{\partial}{\partial \theta_{j}} J(\theta_0,\theta_1) = \frac{\partial}{\partial \theta_{j}} \frac{1}{2m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)})-y^{(i)})^2$

$j=0$时：$\frac{\partial}{\partial \theta_{0}} J(\theta_0,\theta_1) = \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)})-y^{(i)})$

$j=1$时：$\frac{\partial}{\partial \theta_{1}} J(\theta_0,\theta_1) = \frac{1}{m} \sum\limits_{i=1}^{m} ((h_\theta(x^{(i)})-y^{(i)})\cdot{x^{(i)}})$

则算法改写成：

Repeat until convergence{

$\theta_0 := \theta_{0} - \alpha \frac{1}{m}\sum\limits_{i=1}^{m} (h_\theta(x^{(i)})-y^{(i)}) $

$\theta_1 := \theta_{1} - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} ((h_\theta(x^{(i)})-y^{(i)})\cdot{x^{(i)}})$

}

**批量梯度下降**，指的是在梯度下降的每一步中，都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，需要进行求和运算，所以，在每一个单独的梯度下降中，最终都要计算这样一个东西，这个项需要对所有个训练样本$m$求和。

### 多变量线性回归(Linear Regression with Multiple Variables)

$x^{(i)}_j$代表特征矩阵中第$i$行的第$j$个特征，也就是第$i$个训练实例的第$j$个特征。

这个公式中有个$n+1$参数和$n$个变量，为了使得公式能够简化一些，引入$x_0=1$，则公式转化为：

$h_\theta(x)=\theta_0x_0+\theta_1x_1+ \cdots +\theta_nx_n$

此时模型中的参数是一个$n+1$维的向量，任何一个训练实例也都是$n+1$维的向量，特征矩阵$X$的维度是$m\times(n+1)$。 因此公式可以简化为：$h_\theta(x)=\theta^TX$

#### 多变量梯度下降

代价函数：$J(\theta_0,\theta_1,...,\theta_n) = \frac{1}{2m}\sum\limits_{i = 1}^{m}(h_\theta(x^{(i)}) - y^{(i)})^2$

Repeat{

$\theta_j := \theta_{j} - \alpha \frac{1}{m}\sum\limits_{i=1}^{m} ((h_\theta(x^{(i)})-y^{(i)})\cdot x_j^{(i)})$

(simultaneously update $\theta_j$ for $j = 0,1,\cdots,n$

}

计算$J(\theta)$:

```python
def computeCost(X, y, theta):
    inner = np.power(((X * theta.T) - y), 2)
    return np.sum(inner) / (2 * len(X))

```

#### 特征缩放Feature Scaling

在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。

以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。

解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。

归一化(Normalization)：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；

1. min-max归一化 $x_n = \frac{x_n-min(x)}{max(x)-min(x)}$，缩放到0和1之间，但没有改变数据分布
2. mean归一化 $x_n = \frac{x_n-mean(x)}{max(x)-min(x)}$，缩放到-1和1之间。

标准化(Standardization)：将数据变换为均值为0，标准差为1的分布切记，并非一定是正态的；

$x_n = \frac{x_n-\mu_n}{s_n}$，其中$\mu_n$是平均值，$s_n$是标准差。

#### 学习率

梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。

也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看图表更好。

梯度下降算法的每次迭代受到学习率的影响，如果学习率$\alpha$过小，则达到收敛所需的迭代次数会非常高；如果学习率$\alpha$过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。

通常可以考虑尝试些学习率：$\alpha = 0.01, 0.03, 0.1, 0.3, 1, 3, 10$

#### 特征和多项式回归Polynomial Regression

线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：$h_{\theta}(x) = \theta_0+\theta_1x+\theta_2x_2^2$ 或者三次方模型：$h_{\theta}(x) = \theta_0+\theta_1x+\theta_2x_2^2+\theta_3x_3^3$

令 $x_2 = x_2^2,x_3 = x_3^3$，从而将模型转化为多元线性回归模型。

另外，根据函数图形特性，我们还可以使用：

$h_{\theta}(x) = \theta_0+\theta_1x+\theta_2x_2^2$

$h_{\theta}(x) = \theta_0+\theta_1x+\theta_2\sqrt{x_2}$

注：如果采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要！

#### 正规方程Normal Equation

到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，正规方程方法是更好的解决方案。

正规方程是通过求解 $\frac{\partial}{\partial \theta_j}J(\theta_j)=0$ 来找出使得代价函数最小的参数的。

假设训练集特征矩阵为$X_{m\times (n+1)}$ (包含了$x_0=1$)，利用正规方程解出向量 $\theta = (X^TX)^{-1}X^Ty$

$x^{(i)} = \left[ \begin{matrix} x_0^{(i)} \\ x_1^{(i)} \\ x_2^{(i)} \\ \vdots \\ x_n^{(i)}\end{matrix} \right] \in \mathbb{R}^{n+1}$

$X = \left [\begin{matrix} ——(x^{(1)})^T—— \\ ——(x^{(2)})^T—— \\ \vdots \\ ——(x^{(m)})^T—— \end{matrix} \right]_{m\times(n+1)}$

$y = \left[ \begin{matrix} y^{(1)} \\ y^{(2)} \\  \vdots \\ y^{(m)}\end{matrix} \right] \in \mathbb{R}^{m}$

注：正规方程不需要特征缩放！

梯度下降：

- 需要选择学习率$\alpha$，即需要运行多次，尝试不同的学习率，找到效率最好的
- 需要多次迭代
- 当特征数量$n$大时也能较好适用
- 适用于各种类型的模型

正规方程

- 不需要学习率
- 不需要迭代，一次运算得出
- 需要计算$(X^TX)$，如果特征数量$n$较大则运算代价大，因为矩阵逆的计算时间复杂度为$O(n^3)$，通常来说当$n$小于10000时还是可以接受的
- 只适用于线性模型，不适合逻辑回归模型等其他模型

正规方程python

```python
import numpy as np
def normalEqn(X, y):
   theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X等价于X.T.dot(X)
   return theta
```

#### 正规方程在不可逆性情况下解决方法

原因：

1. 特征多余，其中的某些特征线性相关。解决方法：删除线性相关的特征。
2. 特征过多，$m \leq n$。解决方法：删除一些特征，或者正则化。

#### 正规方程推导

$J(\theta_0,\theta_1) = \frac{1}{2m}\sum\limits_{i = 1}^{m}(h_\theta(x^{(i)}) - y^{(i)})^2$

其中：$h_\theta(x)=\theta_0x_0+\theta_1x_1+...+\theta_nx_n$

将向量表达形式转为矩阵表达形式，则有$J(\theta_0,\theta_1) = \frac{1}{2}(X\theta-y)^2$，其中$X$为$m$行$n$列的矩阵（$m$为样本个数，$n$为特征个数），$\theta$为$n$行1列的矩阵，$y$为$m$行1列的矩阵，对$J(\theta)$进行如下变换：

$J(\theta) = \frac{1}{2}(X\theta-y)^T(X\theta-y)$

$= \frac{1}{2}(\theta^TX^T-y^T)(X\theta-y)$

$= \frac{1}{2}(\theta^TX^TX\theta-\theta^TX^Ty-y^TX\theta-y^Ty)$

接下来对$J(\theta)$偏导，需要用到以下几个矩阵的求导法则:

1. $\frac{dAB}{dB}=A^T$
2. $\frac{dX^TAX}{dX}=2AX$

$\frac{\partial J(\theta)}{\partial\theta} = \frac{1}{2}(2X^TX\theta-2X^Ty-0)=(X^TX\theta-X^Ty)$

令$J(\theta)=0$，有：

$θ=(XTX)−1XTy\theta = (X^TX)^{-1}X^Ty$

### 分类

试着推测出离散的输出值

要预测的变量$y$是离散的值，我们将学习一种叫做逻辑回归(**Logistic Regression**)的算法，这是目前最流行使用最广泛的一种学习算法。

将因变量(**dependent variable**)可能属于的两个类分别称为负向类（**negative class**）和正向类（**positive class**），则因变量$y \in 0,1$，其中0表示负向类，1表示正向类。

逻辑回归，该模型的输出变量范围始终在0和1之间。

逻辑回归模型的假设是：$h_\theta(x)=g(\theta^Tx)$，其中：$x$代表特征向量。 $g$代表逻辑函数（**logistic function**)是一个常用的逻辑函数为**S**形函数（**Sigmoid function**），公式为：$g(z)=\frac{1}{1+e^{-z}}$

$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$

```python
import numpy as np
def sigmoid(z):
   return 1 / (1 + np.exp(-z))
```

$h_\theta(x)$的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性（**estimated probablity**）即$h_\theta(x)=P(y=1|x;\theta)$，例如，如果对于给定的$x$，通过已经确定的参数计算得出$h_\theta(x)=0.7$，则表示有70%的几率为$y$正向类，相应地为$y$负向类的几率为1-0.7=0.3。

#### 决策边界decision boundary

![](assets/20211027_154127_1073efb17b0d053b4f9218d4393246cc.jpg)

$z= \theta^Tx \geq 0, h_\theta(x)\geq 0.5$，此时预测$y=1$

$z= \theta^Tx < 0, h_\theta(x)< 0.5$，此时预测$y=0$

![](assets/20211027_160628_f71fb6102e1ceb616314499a027336dc.jpg)

现在假设我们有一个模型：并且参数$\theta$是向量[-3 1 1]。 则当$-3+{x_1}+{x_2} \geq 0$，即${x_1}+{x_2} \geq 3$时，模型将预测 $y=1$。

绘制直线${x_1}+{x_2} = 3$，这条线便是我们模型的分界线，对应$h_\theta(x)=0.5$，将预测为1的区域和预测为0的区域分隔开。

不是用训练集来定义决策边界，而是用训练集来拟合参数$\theta$，一旦有了参数$\theta$，就确定了决策边界。

#### 代价函数

Training Set:$\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\dots ,(x^{(m)},y^{(m)})\}$

m examples: $x \in \left[ \begin{matrix}  x_0 \\ x_1 \\  \vdots \\ x_n \end{matrix} \right] \in \mathbb{R}^{n+1}$, $x_0=1$, $y\in \{0,1\}$

$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$

代价函数：

$J\left( \theta  \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{{Cost}\left( {h_\theta}\left( {x}^{\left( i \right)} \right),{y}^{\left( i \right)} \right)}$

其中

$\operatorname{Cost}\left(h_{\theta}(x), y\right)=\left\{\begin{aligned}-\log \left(h_{\theta}(x)\right) & \text { if } y=1 \\-\log \left(1-h_{\theta}(x)\right) & \text { if } y=0 \end{aligned}\right.$

<<<<<<< HEAD
当实际的 $y=1$ 且 ${h_\theta}\left( x \right)$ 也为1时误差为0，当 $y=1$ 但 ${h_\theta}\left( x \right)$ 不为1时误差随着 ${h_\theta}\left( x \right)$ 变小而变大

当实际的 $y=0$ 且 ${h_\theta}\left( x \right)$ 也为0时代价为0，当 $y=0$ 但 ${h_\theta}\left( x \right)$ 不为0时误差随着 ${h_\theta}\left( x \right)$ 变大而变大
=======
当实际的 $y=1$ 且 ${h_\theta}\left( x \right)$ 也为1时误差为0，当 $y=1$ 但 ${h_\theta}\left( x \right)$ 不为1时误差随着 ${h_\theta}\left( x \right)$ 变小而变大；

当实际的 $y=0$ 且 ${h_\theta}\left( x \right)$ 也为0时代价为0，当 $y=0$ 但 ${h_\theta}\left( x \right)$ 不为0时误差随着 ${h_\theta}\left( x \right)$ 变大而变大。
>>>>>>> 0e3eb5a (2021.11)

将构建的 $Cost\left( {h_\theta}\left( x \right),y \right)$简化如下：

$Cost\left( {h_\theta}\left( x \right),y \right)=-y\times log\left( {h_\theta}\left( x \right) \right)-(1-y)\times log\left( 1-{h_\theta}\left( x \right) \right)$

带入代价函数得到：

$J\left( \theta  \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( {h_\theta}\left( {{x}^{(i)}} \right) \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1-{h_\theta}\left( {{x}^{(i)}} \right) \right)]}$

即：$J\left( \theta  \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{{y}^{(i)}}\log \left( {h_\theta}\left( {{x}^{(i)}} \right) \right)+\left( 1-{{y}^{(i)}} \right)\log \left( 1-{h_\theta}\left( {{x}^{(i)}} \right) \right)]}$

(统计学中的极大似然法)

在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为：

$min_\theta J(\theta)$

Repeat:{
$\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)$
(simultaneously update all)
}

求导后得到：

Repeat: {
$\theta_j := \theta_j - \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{{\left( {h_\theta}\left( \mathop{x}^{\left( i \right)} \right)-\mathop{y}^{\left( i \right)} \right)}}\mathop{x}_{j}^{(i)}$
(simultaneously update all)
}

推导：

${h_\theta}\left( {{x}^{(i)}} \right)=\frac{1}{1+{{e}^{-{\theta^T}{{x}^{(i)}}}}}$

则：

${{y}^{(i)}}\log \left( {h_\theta}\left( {{x}^{(i)}} \right) \right)+\left( 1-{{y}^{(i)}} \right)\log \left( 1-{h_\theta}\left( {{x}^{(i)}} \right) \right)$

$={{y}^{(i)}}\log \left( \frac{1}{1+{{e}^{-{\theta^T}{{x}^{(i)}}}}} \right)+\left( 1-{{y}^{(i)}} \right)\log \left( 1-\frac{1}{1+{{e}^{-{\theta^T}{{x}^{(i)}}}}} \right)$

$=-{{y}^{(i)}}\log \left( 1+{{e}^{-{\theta^T}{{x}^{(i)}}}} \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1+{{e}^{{\theta^T}{{x}^{(i)}}}} \right)$

所以：

$\frac{\partial }{\partial {\theta_{j}}}J\left( \theta  \right)=\frac{\partial }{\partial {\theta_{j}}}\{-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( 1+{{e}^{-{\theta^{T}}{{x}^{(i)}}}} \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1+{{e}^{{\theta^{T}}{{x}^{(i)}}}} \right)]}\}$

$=-\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\frac{-x_{j}^{(i)}{{e}^{-{\theta^{T}}{{x}^{(i)}}}}}{1+{{e}^{-{\theta^{T}}{{x}^{(i)}}}}}-\left( 1-{{y}^{(i)}} \right)\frac{x_j^{(i)}{{e}^{{\theta^T}{{x}^{(i)}}}}}{1+{{e}^{{\theta^T}{{x}^{(i)}}}}}}]$

$=-\frac{1}{m}\sum\limits_{i=1}^{m}{{y}^{(i)}}\frac{x_j^{(i)}}{1+{{e}^{{\theta^T}{{x}^{(i)}}}}}-\left( 1-{{y}^{(i)}} \right)\frac{x_j^{(i)}{{e}^{{\theta^T}{{x}^{(i)}}}}}{1+{{e}^{{\theta^T}{{x}^{(i)}}}}}]$

$=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{{{y}^{(i)}}x_j^{(i)}-x_j^{(i)}{{e}^{{\theta^T}{{x}^{(i)}}}}+{{y}^{(i)}}x_j^{(i)}{{e}^{{\theta^T}{{x}^{(i)}}}}}{1+{{e}^{{\theta^T}{{x}^{(i)}}}}}}$

$=-\frac{1}{m}\sum\limits_{i=1}^{m}{\frac{{{y}^{(i)}}\left( 1\text{+}{{e}^{{\theta^T}{{x}^{(i)}}}} \right)-{{e}^{{\theta^T}{{x}^{(i)}}}}}{1+{{e}^{{\theta^T}{{x}^{(i)}}}}}x_j^{(i)}}$

$=-\frac{1}{m}\sum\limits_{i=1}^{m}{({{y}^{(i)}}-\frac{{{e}^{{\theta^T}{{x}^{(i)}}}}}{1+{{e}^{{\theta^T}{{x}^{(i)}}}}})x_j^{(i)}}$

$=-\frac{1}{m}\sum\limits_{i=1}^{m}{({{y}^{(i)}}-\frac{1}{1+{{e}^{-{\theta^T}{{x}^{(i)}}}}})x_j^{(i)}}$

$=-\frac{1}{m}\sum\limits_{i=1}^{m}{[{{y}^{(i)}}-{h_\theta}\left( {{x}^{(i)}} \right)]x_j^{(i)}}$

$=\frac{1}{m}\sum\limits_{i=1}^{m}{[{h_\theta}\left( {{x}^{(i)}} \right)-{{y}^{(i)}}]x_j^{(i)}}$

**补充：**

$P\left( y=1|x;\theta \right)=h_\theta \left( x \right)$

$P\left( y=0|x;\theta \right)= 1 - h_\theta \left( x \right)$

上面两式可以写成一般形式

$P\left( y|x;\theta \right)= (h_\theta \left( x \right))^y (1 - h_\theta \left( x \right))^{1-y}$

接下来我们就要用极大似然估计来根据给定的训练集估计出参数 $\theta$。

$L(\theta) = \prod \limits_{i=1}^{n}P(y^{(i)}|x^{(i)};\theta)=\prod \limits_{i=1}^{n}(h_\theta ( x^{(i)} ))^{y^{(i)}} (1 - h_\theta(x^{(i)} )^{1-y^{(i)}}$

两边取对数：

$l(\theta)=ln L(\theta)=\sum \limits_{i=1}^{n}y^{(i)} ln(h_\theta ( x^{(i)} )) + (1-y^{(i)}) ln(1 - h_\theta(x^{(i)})$

要求使得 $l(\theta) $ 最大的 $\theta$，加上负号，即为使代价函数最小。

$J(\theta)=-l(\theta)=-\sum \limits_{i=1}^{n}(y^{(i)} ln(h_\theta ( x^{(i)} )) + (1-y^{(i)}) ln(1 - h_\theta(x^{(i)}))$

Sigmoid function有一个很好的性质是

$\phi(z)=\frac{1}{1+e^{(-z)}}$

$\phi(z)^{'} = \phi(z)(1-\phi(z))$

$\frac{\partial }{\partial {\theta_{j}}}J(\theta)=-\sum\limits_{i=1}^{m}{({{y}^{(i)}}\frac{1}{\phi(z^{(i)})}-( 1-{{y}^{(i)}})\frac{1}{1-\phi(z^{(i)})}}) \frac{\partial{\phi(z^{(i)})}}{\partial{\theta_j}}$

$= -\sum\limits_{i=1}^{m}({{y}^{(i)}\frac{1}{\phi(z^{(i)})}-( 1-{{y}^{(i)}})\frac{1}{1-\phi(z^{(i)})}})\phi({z^{(i)}})(1-\phi({z^{(i)}}) \frac{\partial z^{(i)}}{\partial\theta}$

$ = -\sum\limits_{i=1}^{m} (y^{(i)}(1-\phi({z^{(i)}})-(1-y^{(i)})\phi({z^{(i)}})){x^{(i)}}$

$=-\sum \limits_{i=1}^{m}(y^{(i)}-\phi({z^{(i)}}))x^{(i)}$

$=-\sum \limits_{i=1}^{m}(y^{(i)}-\phi({z^{(i)}}))x^{(i)}$

$=\sum\limits_{i=1}^{m}{({h_\theta}\left( {{x}^{(i)}} \right)-{{y}^{(i)}})x_j^{(i)}}$

注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。

一些梯度下降算法之外的选择：
除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：**共轭梯度**（**Conjugate Gradient**），**局部优化法**(**Broyden fletcher goldfarb shann,BFGS**)和**有限内存局部优化法**(**LBFGS**)。

这三种算法有许多优点：

1. 通常不需要手动选择学习率 $\alpha$，所以对于这些算法的一种思路是，给出计算导数项和代价函数的方法，你可以认为算法有一个智能的内部循环，而且，事实上，他们确实有一个智能的内部循环，称为**线性搜索**(**line search**)算法，它可以自动尝试不同的学习速率 $\alpha$，并自动选择一个好的学习速率 $\alpha$，甚至可以为每次迭代选择不同的学习速率，不需要自己选择。
2. 比梯度下降收敛得快得多

缺点：更复杂

#### 多类别分类：一对多

将多个类中的一个类标记为正向类（$y=1$），然后将其他所有类都标记为负向类，这个模型记作$h_\theta^{\left( 1 \right)}\left( x \right)$。接着，类似地选择另一个类标记为正向类（$y=2$），再将其它类都标记为负向类，将这个模型记作 $h_\theta^{\left( 2 \right)}\left( x \right)$，依此类推。

最后得到一系列模型简记为： $h_\theta^{\left( i \right)}\left( x \right)=p\left( y=i|x;\theta  \right)$其中：$i=\left( 1,2,3....k \right)$

最后，在需要做预测时，将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。

总之，就是训练这个逻辑回归分类器：$h_\theta^{\left( i \right)}\left( x \right)$， 其中 $i$ 对应每一个可能的 $y=i$，最后，输入一个新的 $x$ 值用来做预测。要做的就是在所有分类器里面输入 $x$，然后选择一个让 $h_\theta^{\left( i \right)}\left( x \right)$ 最大的 $ i$，即$\mathop{\max}\limits_i\,h_\theta^{\left( i \right)}\left( x \right)$。

### 正则化

#### 过拟合Overfitting

1. 欠拟合：Underfitting，bias偏差较高
2. 过拟合：Overfitting，variance方差较高，代价函数很小甚至为0，泛化能力很差

解决：

1. 丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如**PCA**）
2. 正则化。 保留所有的特征，但是减少参数的大小（**magnitude**）。

$J\left( \theta  \right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}{{{({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})}^{2}}+\lambda \sum\limits_{j=1}^{n}{\theta_{j}^{2}}]}$

其中 $\lambda$ 又称为正则化参数（**Regularization Parameter**）。 注：根据惯例，我们不对${\theta_{0}}$ 进行惩罚。

如果选择的正则化参数 $\lambda$ 过大，则会把所有的参数都最小化了，导致模型变成 ${h_\theta}\left( x \right)={\theta_{0}}$，造成欠拟合。

如果我们令 $\lambda$ 的值很大的话，为了使**Cost Function**尽可能的小，所有的 $\theta$ 的值（不包括${\theta_{0}}$）都会在一定程度上减小。但若 $\lambda$ 的值太大，那么$\theta$（不包括${\theta_{0}}$）都会趋近于0，这样我们所得到的只能是一条平行于$x$轴的直线。所以对于正则化，我们要取一个合理的 $\lambda$ 的值，这样才能更好的应用正则化。

#### 线性回归正则化

$J\left( \theta  \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{[({{({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})}^{2}}+\lambda \sum\limits_{j=1}^{n}{\theta _{j}^{2}})]}$

Repeat until convergence{

${\theta_0}:={\theta_0}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})x_{0}^{(i)}})$

${\theta_j}:={\theta_j}-\alpha[\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})x_{j}^{\left( i \right)}}+\frac{\lambda }{m}{\theta_j}]$  for $j=1,2,...n$

}

只对 $\theta_1,\theta_2,\cdots,\theta_n$ 惩罚，不惩罚 $\theta_0$

对上面的算法中 $ j=1,2,...,n$ 时的更新式子进行调整可得：

${\theta_j}:={\theta_j}(1-\alpha\frac{\lambda }{m})- \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})x_{j}^{\left( i \right)}}$

（$\alpha$ 很小，$m$ 很大，所以 $\alpha \frac{\lambda}{m}$ 非常小）

可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令 $\theta $ 值减少了一个额外的值，然后进行和之前一样的更新操作。

同样也可以利用正规方程来求解正则化线性回归模型：

$\theta=\left(X^{T} X+\lambda\left[\begin{array}{cccc}0 & & & \\ & 1 & & \\ & & 1 & \\ & & & \ddots& \\ & & & & 1\end{array}\right]\right)^{-1} X^{T} y$

矩阵尺寸为 $(n+1)\times(n+1)$

不可逆情况讨论：如果 $\lambda>0$，则$\left(X^{T} X+\lambda\left[\begin{array}{cccc}0 & & & \\ & 1 & & \\ & & 1 & \\ & & & \ddots& \\ & & & & 1\end{array}\right]\right)^{-1}$一定可逆

#### 逻辑回归正则化

$J\left( \theta  \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{{y}^{(i)}}\log \left( {h_\theta}\left( {{x}^{(i)}} \right) \right)-\left( 1-{{y}^{(i)}} \right)\log \left( 1-{h_\theta}\left( {{x}^{(i)}} \right) \right)]}+\frac{\lambda }{2m}\sum\limits_{j=1}^{n}{\theta _{j}^{2}}$

```python
import numpy as np

def costReg(theta, X, y, lambda):
    theta = np.matrix(theta)
    X = np.matrix(X)
    y = np.matrix(y)
    first = np.multiply(-y, np.log(sigmoid(X*theta.T)))
    second = np.multiply((1 - y), np.log(1 - sigmoid(X*theta.T)))
    reg = (lambda / (2 * len(X))* np.sum(np.power(theta[:,1:theta.shape[1]],2))
    return np.sum(first - second) / (len(X)) + reg
```

Repeat until convergence{

${\theta_0}:={\theta_0}-\alpha \frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})x_{0}^{(i)}})$

${\theta_j}:={\theta_j}-\alpha[\frac{1}{m}\sum\limits_{i=1}^{m}{(({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})x_{j}^{\left( i \right)}}+\frac{\lambda }{m}{\theta_j}]$  for $j=1,2,...n$

}

<<<<<<< HEAD
注：看上去同线性回归一样，但是 ${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$ 与线性回归 $h_\theta(x)=\theta_0x_0+\theta_1x_1+ \cdots +\theta_nx_n$ 不同，所以与线性回归本质不同。
=======
注：看上去同线性回归一样，但是 ${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$ 与线性回归 $h_\theta(x)=\theta_0x_0+\theta_1x_1+ \cdots +\theta_nx_n$ 不同，所以与线性回归本质不同。
>>>>>>> 0e3eb5a (2021.11)
