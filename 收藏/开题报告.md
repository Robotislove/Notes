# 开题报告

选题意义
该领域国内外研究动态（文献综述）
本课题研究的目的
预期成果
研究方案
研究方法及其论证
关键难点拟采取的解决措施
论文工作总体日程安排
预计答辩时间

## 1. 研究背景及意义

近年来，图像和视频编码技术飞速发展。然而由于图像和视频采集设备的普及，图像和视频数据的增长速度远远超过了压缩性能的提高。

研究人员渐渐认识到，在传统混合编码框架内追求进一步的编码性能改进面临着越来越大的挑战。深度神经网络是近年来兴起的神经网络，在人工智能领域取得了巨大的成功，也为图像和视频压缩提供了一种可行的解决方案。

利用深度学习和HEVC框架的视频编码技术，这些技术大大提高了视频编码的性能。

基于神经网络的端到端图像和视频编码框架，揭示了下一代图像和视频编码框架/标准的有趣探索。

对语义信息和视觉信息的联合压缩进行了尝试性的探索，以期为人工智能时代占主导地位的人类视觉和机器视觉构建了高效的信号表示结构。

在有限的传输网络和存储能力下，图像和视频压缩在提供高质量的图像和视频服务方面发挥着重要作用。图像和视频压缩的基础是图像和视频中的冗余，包括空间冗余、视觉冗余和统计冗余，同时，视频序列中存在的时间冗余性使得视频压缩比图像压缩具有更高的压缩比。

对于图像压缩，早期的方法主要是直接利用熵编码来减少图像内的统计冗余来实现压缩，如霍夫曼编码[1]、Golomb码[2]和算术编码[3]。在20世纪60年代后期，变换编码被用于图像压缩，包括傅立叶变换[4]和阿达玛变换[5]。1974年，Ahmed等人提出了用于图像编码的离散余弦变换(DCT)[6]，它可以在低频域压缩图像信息，从而使频域压缩更高效。

除了通过熵编码和变换技术减少统计冗余外，研究人员还提出了预测和量化技术来减少图像中的空间冗余和视觉冗余。JPEG作为目前最流行的图像压缩标准，融合了以往的编码技术，首先将图像分成块，然后将块变换到DCT域。对每个块的DC分量进行差分脉冲编码调制(DPCM)[7]，使得相邻DCT块之间的DC分量的预测残差被压缩，而不是直接压缩DC值。为了减少视觉冗余，JPEG设计了一个特殊的量化表，在很好地保留低频信息的同时舍弃了大量的高频(类噪声)信息，因为人类对高频部分的信息丢失不那么敏感[8]。另一个著名的图像压缩标准JPEG2000[9]采用2D小波变换代替DCT，并利用一种高效的算术编码方法EBCOT[10]来减少小波系数中存在的统计冗余。

对于视频编码，由于连续帧之间的高度相关性，时间冗余成为主要冗余，时间冗余可以通过帧间预测来消除。为了有效地获取帧间预测，在20世纪70年代提出基于块的运动预测[11]。1979年，Netravali和Stuller提出了运动补偿变换框架[12]，现在被称为混合预测/变换编码器。

经过几十年的发展，预测变换混合编码方法取得了巨大的成功。研究人员开发出MPEG-1/2/4、H.261/2/3和H.264/AVC[14]，以及AVS(中国音视频编码标准)[15]和HEVC[16]等许多编码标准并广泛应用。

以最新的视频编码标准HEVC为例，它利用相邻的重构像素来预测当前编码的编码块，具有33种角度帧内预测模式，DC模式和平面模式，如图1所示。

对于帧间编码，HEVC从多个角度进一步改进了编码性能，如增加PU分割的分集，利用更多的插值过滤抽头进行亚采样运动补偿[17]，以及细化边信息编码，包括更多的概率更高的边信息编码。对于帧间编码，HEVC从多个角度进一步改进以提升编码性能，例如增加PU分割的分集，利用更多的插值滤波进行亚采样运动补偿[17]，以及细化包括最大概率在内的边信息编码用于帧内模式编码，高级运动矢量预测(AMVP)和合并模式[19]用于运动矢量预测器编码。目前最先进的视频编码框架中的另一种新的视频编码工具是环路滤波，自2000年以来已经提出了许多环路滤波器[20]-[25]，HEVC采用的是去块滤波[26]、[27]和SAO滤波[28]。然而，传统的基于图像和视频局部相关性的混合视频编码框架的细化策略越来越难以进一步提高编码效率。

近年来，神经网络，特别是卷积神经网络(CNN)在图像视频理解、处理和压缩等领域取得了巨大的成功。一个卷积神经网络通常由一个或多个卷积层组成。具体地说，一些任务还在卷积层之后有几个全连接的层。这些层中的参数可以基于端到端策略中为特定任务标记的大量图像和视频样本来很好地训练。训练好的卷积神经网络可以很好地应用于解决图像视频的分类、识别和预测任务。

卷积神经网络模型的效果已经超过了基于规则的模型效果。此外，卷积神经网络还可以作为特征提取器，将图像和视频转换到具有紧凑表示的特征空间，从而更好的进行图像和视频压缩。

第二节，神经网络和图像视频压缩的基本概念
第三节，基于神经网络的图像压缩技术的发展，进一步理论基础主要是从网络发展的时间轴出发，介绍基于典型网络结构的基于神经网络的图像压缩方法
第四节，基于神经网络的视频压缩技术的发展，主要介绍了目前最先进的混合视频编码框架HEVC中嵌入的基于CNN的视频编码技术，并介绍了一些新的基于CNN的视频编码框架
第五节，基于神经网络的图像和视频压缩优化技术

## 2. 国内外研究现状

## 3. 研究目标及研究内容

## 4. 技术路线

## 5. 实验进展

## 6. 论文进度安排

# 图像压缩

图像压缩标准通用框架图

## 引言

图像压缩一直是图形图像处理领域的基础课题，对图像压缩的研究从未

在有了BP算法[1]之后，就已经有研究人员将神经网络引入图像压缩领域的先例，之后随着深度学习地不断深入研究，基于深度学习的图像压缩方法也随之被提出。

深度学习[2]对图像特征提取、表达能力，以及高维数据的处理能力等都被认为对于图像压缩存在独有的优势，时至今日研究这一方向的人数日益增多，将深度学习应用于图像压缩逐渐成为当前的热点研究问题之一。

传统的图像编码标准如：JPEG[3]、JPEG2000[4]和BPG已被广泛使用，传统的图像压缩多采用固定的变换方式和量化编码框架，如离散余弦变换和离散小波变换，在结合量化和编码器来减少图像的空间冗余，但是并非所有类型的图像都适用于这种方式，如以图像块的方式进行变换量化后会有块效应。同时在大量传输图像时由于网络带宽的限制，为了实现低比特位率编码，会导致图像的模糊[5]现象。

深度学习技术可以根据自身特点优化上述问题：如在编码器的性能上，深度学习技术可以对编码器和解码器进行联合优化，不断提升编码器的性能；在图像清晰度上，基于深度学习的图像超分辨率[6]技术，以及生成对抗网络都能使图像重建更加清晰；在面对不同类型的图像，针对不同类型的任务上，深度学习技术能够根据任务的特点对图像实现更智能、更针对的编解码。

## 传统图像编码

图像压缩的目的是通过消除数字图像像素间的冗余实现图像压缩处理。在静态图像中，空间冗余是存在的最多的冗余，

JPEG、PNG、BPG。

传统的图像压缩方法采用变换方式再配合熵编码进行图像压缩，而深度学习则是采用端到端的结构设计和不同种类的网络经过训练替代传统的固定变换方式，进而提升图像压缩的性能。

同时近些年GPU的高速发展，也为性能的提升提供了硬件支持，是基于深度学习的图像压缩在分辨率、比特率等方面有了提高。

---

## 基于深度学习的图像压缩方法

图像压缩根据对编码信息的恢复程度来进行分类，主要分为无损压缩[10]和有损压缩[11]，基于深度学习的图像压缩方法多为有损图像压缩，依赖深度学习强大的建模能力，基于深度学习的图像压缩性能已经超过了 JPEG 和 BPG，并且这种性能上的差距仍在逐步扩大。

下面将分别对基于卷积神经网络(Convolutional Neural Network，CNN)[12]、循环神经网络(Recurrent Neural Network，RNN)[13]、生成对抗网络(Generative Adversarial Network，GAN)[14]进行介绍。

### 端到端图像视频压缩的优势

首先，端到端图像视频压缩可以在保留像素级内容的同时保留图像视频内容中高层语义信息，该语义信息可以随后被后续的智能分析任务进一步挖掘。也就是说，编码的参数可以根据特定的语义任务自动调整。这一优势在传统的图像视频编码方法中难以实现，因为其各模块通常是单独优化的，难以集成特定的度量准则。

其次，端到端的图像视频压缩可以生成结构化码流，而非现有的没有语义结构的二进制流。在码流结构化的前提下，一些智能任务可以很方便的展开。例如，在特殊情况下可以只传输解码部分内容，而无需对整张图像做解码操作，这节省了较多的传输、计算代价。同时，智能的后续任务可以轻易的在部分码流上直接实现，省去了解码操作。

最后，端到端的图像视频压缩能够建模、分解图像视频中特定的语义内容并将语义内容以更高效的形式存储。这种高效的存储模式不仅可以减少传输和存储的代价，同时能够指导其他语义任务的进一步处理。

---

# 视频压缩

视频作为承载了海量非结构化数据和应用最广泛的多媒体数据格式已与人们的生活密不可分，是人类获得信息的重要途径之一。与视频相关的各种技术问题都得到了广泛关注。

在视频技术的发展过程中，从模拟到数字的转换是一次伟大的技术革，由此带来了数字信号处理等理论的构建，为该领域的持续发展奠定了基础。

继数字化、高清化之后，视频技术正在经历由超高清和智能化等新一轮技术革新带来的跨越式发展。

在视频压缩领域，国际电报电话咨询委员会(Consultative Committee of International Telegraph and Telephone，CCITT) 于 1984 年颁布了首个视频压缩国际标准 H.120。

视频行业的核心需求是将视频实时高清地呈现给用户，技术基础是视频处理和压缩。一方面，视频在获取过程中不可避免地会引入信号失真，为提高视频用户体验，对视频进行实时高效的处理，提高视频质量非常必要。另一方面，产业规模的扩大和应用场景的拓宽衍生了海量非结构化视频数据，高效地传输和存储是确保视频产业健康发展的基础，而视频压缩技术正是实现视频紧致表达的关键。面向视频产业的发展需求。

本文将归纳视频压缩和处理的国内外发展现状，分析该领域的关键技术，并展望未来发展空间。

## 视频处理技术

### 视频超分辨率

在基于深度学习的超分辨率算法中，出现了许多基于深度神经网络的超分辨率方法，包括基于卷积神经网络、循环神经网络和生成对抗网络的视频超分辨方法。

2014 年 Dong 等人首次将卷积神经网络与图像的超分辨率重建任务相结合，提出了适用于图像超分的 SRCNN[34]网络，他们使用一个仅有 3 层卷积层的网络来对图像超分进行建模，却在质量与速度指标上都达到了当时的最优效果，并且远超之前的一些基于传统学习和基于插值的方式，展现出了神经网络在这一任务上的强大优势。并且他们证明了 SRCNN 算法的每一层网络都对应了稀疏编码算法中的一个步骤，从而将深度学习与传统学习的方式进行了有机的统一。之后他们对原先网络的输入进行改进，将低分图像直接作为输入，使得网络可以学习到高、低分图像之间的非线性映射，从而对网络进行加速，并命名为 FSRCNN [35]。

Wang[36]等人将 CNN 与稀疏编码结合以提升模型的鲁棒性。Johnson[37]等人则引入感知损失函数，从特征域的角度对重建结果进行评估。Shi[38]等人提出的 ESPCN 则使用亚像素卷积层直接生成低分辨图像，并且具有很好的实时性和效果。由于深度残差网络可以解决网络优化困难的问题，因此也有很多网络将这种结构引入进来，从而可以提升网络的深度和表达能力。

由于视频和图像的联系，因此大部分的视频超分辨算法是由图像超分辨率演变来的，这类算法在使用单帧图像的信息同时还考虑到了帧间运动信息等高频信息，从而来提升重建的结果。一般来说，视频超分辨率算法通常需要解决两个问题: 运动估计和图像恢复。运动估计的目的估计低分图像帧之间的运动，将相邻帧与参考帧做帧间对齐，使之位于同一坐标系下，这样一来，相邻帧就包含了目标帧在时空上的微小改变，从而增加其所包含的信息；之后通过图像恢复技术研究如何更好地利用这些信息来得到最终结果。Cheng 等人首次将基于学习的方法应用于视频超分辨率中。随后 Kappeler[39]等人将 SRCNN 结构做了改进，使之可以被用于多帧图像输入，提出了适用于视频超分辨率的 CNN 基本结构。之后的一些学者同样聚焦在这一问题上，这些算法的最终目的都是提高算法的准确性、实时性以及应用范围。视频超分辨率相对图像超分辨率来说，有着更加广阔的使用价值和应用前景。

目前，超分辨率算法主要有以下几个重要的发展趋势:

1. 设计更加高效、快捷的图像超分辨率算法。由于图像和视频的联系，因此如果能在单帧图像上获得更好效果的算法，可类比到视频使用之上，因此它对视频超分辨率算法有着十分重要的启示作用。因此，有大量的研究人员着眼于寻找更加全面、合适的图像先验分布模型，力求在图像上取得更好的效果。
2. 设计更高效和先进的网络结构，加深网络结构、引入循环卷积[40] 方式，采用更加先进的运动补偿算法。循环卷积能够有效地利用时序信息，显示的运动补偿算法则更加直观和具有可解释性，不过它们的主要目标任是如何更加有效地利用帧间的互补信息，使得视频超分辨率的效果更好。
3. 随着生成对抗网络的发展，以及在一些图像生成应用[41]上的成功。一些研究人员受此启发，开始考虑放弃传统的基于高、低分辨率图像对以学习映射关系的方法，转而使用 GAN 来直接生成效果更好的视频超分辨率结果[42–44]。但是直接套用现有的 GAN 网络生成的图片存在抖动，因此如何保证生成视频图像的一致性和连续性，仍然是一个难题。
4. 算法效率和鲁棒性的提升。当前基于学习的超分辨率算法往往需要大量的训练数据和运行时长，同时有些算法只在某些数据集上有较好的表现，但缺乏泛化能力。因此提高算法效率和鲁棒性，吸引了众多研究人员的注意力。

视频超分辨率算法分为对齐超分算法和非对齐的超分算法。

Kelvin[BasicVSR]等人深入总结分析了视频超分辨率的四个最基本组件(传播、对齐、聚合和上采样) 通过重用一些现有的最优组件，并进行及其微少的重新设计，设计了一个简洁的pipeline--BasicVSR，与许多最先进的算法相比，该方法在速度和恢复质量方面都有明显的提高。

---

### 视频插帧

在视频插帧研究方面，Meyer 等人(2018)基于相位的运动表示提出了 PhaseNet 结构，对运动模糊或闪动变化产生了比较鲁棒的结果，但不能有效重建详细的纹理。

核方法在 2017 年是一个研究热点，Niklaus 等人(2017a，b) 连续在 ICCV (IEEE International Conference on Computer Vision) 和 CVPR (IEEE Conference of Computer Vision and Pattern Recognition) 会议上提出了基于核的方法，为每个像素估计一个自适应卷积核。 基于核的方法可以产生合理的结果，但是不能处理大运动场景。 为了有效利用运动信息，Niklaus 和 Liu(2018) 使用前向 变形技术从连续的两帧中生成了中间帧，然而前向扭曲矫正存在像素缺失和重叠。因此，大多数基于流的算法都是基于反向扭曲矫正的。为了使用反向扭曲，需要估计中间运动(即中间帧的运动向量) 。

---

## 视频压缩技术

### 混合框架

传统视频编码采用基于块划分的混合编码框架，包括帧内预测、帧间预测、变换、量化、熵编码和环路滤波等技术模块。这些模块经过几十年的发展已逐渐成熟。

利用最新的视频编码标准HEVC进行基于深度学习的视频编码的研究是近年来的一个活跃领域。HEVC中几乎所有的模块都通过融合各种深度学习模型进行了探索和改进。

---

### 端到端视频压缩框架

尽管精心设计的混合视频编码框架有着优异的压缩性能，但进一步提高性能难度越来越大，此外，也对算力提出了更高的需求。

与基于神经网络的图像编码框架类似，通过组装不同的神经网络模型，研究人员提出了一些新颖的视频编码框架。Chen等人通过几个卷积网络的组合，称为DeepCoder，实现了与低质量X264编码器相似的效果[114]。在DeepCoder中，通过神经网络来进行帧内预测，以生成一个特征映射，记为fMap，而帧间预测是通过对先前帧的运动估计来实现。fMap被进一步量化并编码成流。利用神经网络将帧内和帧间预测残差变换到一个更紧凑的特征空间中，其过程类似于帧内预测中fMap的生成过程，但神经网络参数不同。使用霍夫曼熵编码对帧内预测和残差生成的fMap进行量化和编码。虽然没有H.264/AVC那么多的编码工具，但与H.264/AVC相比，DeepCoder显示出与H.264/AVC相当的压缩性能，这为视频编码提供了一种新的思路。

Chen等人提出了一种完全基于学习的视频编码框架，通过引入VoxelCNN的概念，探索时空相关性来有效地执行预测编码[115]，该视频编码框架可分为预测编码、迭代分析/合成和二值化三个模块。VoxelCNN被设计用来预测视频序列中的块，条件是先前编码的帧以及几个具有相邻级之间连接的基于LSTM的自动编码器的相邻块。随后，利用Toderici等人[63]的RNN模型对预测信号与原始信号之差的紧凑离散表示进行迭代分析与综合，该模型由多个基于LSTM的自动编码器组成，并在相邻级之间连接，最后，经过二值化和熵编码后得到比特流。虽然他们目前的工作中缺乏熵编码，但该方案仍显示出与H.264/AVC相当的性能，显示出其在未来视频编码中的潜力。

受生成模型的未来帧预测启发[116]，Sriastava等人提出了利用LSTM(Long Short Term Memory)编解码器框架来学习[117]中的视频表示，可以用来预测未来的视频帧。该视频框架主要有两个模型，LSTM自动编码器模型和LSTM未来预测器模型，由两个递归神经网络组成。与Ranzato的工作[116]仅预测一个未来帧不同，该模型可以预测到未来较长序列。实验证明，利用输入的16个自然视频帧，该模型可以重建这16帧，并对未来的13帧进行预测。

## 加速

### GAN模型压缩

生成对抗网络是深度神经网络应用中最具吸引力的网络之一。GAN的思想是对抗和博弈，在对抗中不断发展，一个生成器通过输入噪声样本进行生成数据，一个判别器用于接收生成器生成的数据和真实的数据样本，并且对输入的真实数据和生成数据做出正确的判断，通过对生成器和判别器的不断对抗，使网络架构得到优化。

生成器和判别器可通过端到端学习的方法同时优化，判别器判断生成器生成的样本是否为真，同时生成器通过在目标函数中加入对抗损失函数不断根据采样信号生成高质量样本数据，使得判别器无法区分生成样本之真实性。在图像压缩任务中，GAN的这一特性能够用于提升生成图像的主观质量，从而提升压缩性能。在图像压缩任务中，一些研究工作着眼于解码图像的感知质量，并利用GAN来提高编码性能。

Rippel[65]提出利用GAN处理图像压缩的任务，优化后的基于GAN的图像压缩算法压缩比显著地提高。如图9所示，输入图像通过网络被压缩到非常紧凑的特征空间中，在恢复时，利用生成网络从特征重构解码图像。基于GAN的图像压缩与基于CNN或RNN的图像压缩最明显的区别在于引入了对抗性损失，显著提高了重建图像的主观质量。通过联合训练生成器和判别器来显著提高产生式模型的性能。[65]中基于GAN的方法实现了显著的压缩比改进，例如，在所有质量级别的通用图像上，产生的压缩文件比JPEG和JPEG2000小2.5倍，比WebP小2倍，比BPG小1.7倍。此外，GAN生成的内容比特定的纹理更符合原始内容的语义，在放大重建图像时，可以看到特定纹理中的内容差异。

此外，Gregor等人将齐次深生成卷积模型Draw[67]引入到图像压缩任务中。与前人的工作不同的是，Gregor等人希望通过生成尽可能多的图像语义信息来进行概念性压缩[68]。他们详细探索了一种基于GAN的极端图像压缩框架，其目标比特率低于0.1bpp，且允许不同程度的内容生成[69]。目前，基于GAN的压缩方法在人脸图像中已经取得了成功，对一般自然图像的建模还有待进一步研究。

虽然目前基于GAN的图像压缩算法已经取得了相当好的效果，相较于通用图像压缩算法，基于GAN的图像压缩算法可以实现50倍的压缩比，并且恢复效果相比于通用压缩算法也更好，然而基于GAN的图像压缩算法也存在速度慢的问题。由于深度模型堆叠了许多卷积网络，因此推理速度会较慢，经实际场景实验验证，在GeForce 2080GPU下，单张图片需要880
ms的推理速度。

根据资料，人类的正常反应速度为200-300ms，因此当图像恢复时间小于200ms时，人才不会感觉到明显的延迟，因而需要提高对当前基于GAN的图像压缩算法推理速度。

由于 GAN 对计算资源和存储空间的需求巨大，模型难以直接部署到手机、Pad 等移动设备上，业界一直在努力改进 GAN 的压缩方法。2020 年，麻省理工学院、Adobe 和上海交通大学的研究者们提出一种 GAN 压缩算法，将算力消耗成功减少到 1/21。

字节跳动提出的 OMGD 方法则进一步提升了压缩能力。OMGD（Online Multi-Granularity Distillation）意为“在线多粒度蒸馏”，该算法能灵活地在训练过程中优化并压缩 GAN 模型，从而实现更好的图像效果和更少的计算成本。OMGD 压缩算法对 Pix2Pix 和 CycleGAN 这两种常用的 GAN 解决方案效果显著。Pix2Pix 和 CycleGAN 主要应用于图像到图像的“翻译”，比如将照片转换为绘画，对黑白图片着色等。OMGD 压缩算法可使其算力消耗分别减少到原来的 1/40 和 1/46。

## 优化

目前最先进的视频编码标准 HEVC 通过穷举所有可能的编码模式和分区来根据率失真代价确定最优的编码参数，从而实现最佳的压缩性能。通过预测最佳编码参数以跳过不必要的率失真计算，可以极大地降低计算成本。研究人员提出了基于神经网络分别提出了编码单元（CU）和预测单元（PU）的快速模式选择算法，该算法不仅并行计算效果好，而且易于VLSI设计[118]，[119]。此快速算法首先基于局部梯度进行粗略分析，将块划分为同质和边缘类别。这种策略不仅可以减轻CNN的负担，而且可以使CNN避免由于同质块而导致的问题。然后，为边缘块设计CNN，为每个CTU中减少不少于两个CU划分模式，进行全率失真优化处理。模型中所设计的网络包含一个卷积层和一个最大池化层，然后是三个全连接层，并在最后一个全连通层将QP值带入网络。每个正方形CU作为网络输入，输出是当前CU的四分或不划分的二元判决，因此消除了递归模式遍历和选择过程。与HM-12.0相比，他们的方法平均节省了61.1%的帧内编码时间，而BD率损失仅为2.67%。Xu等人通过使用CNN和LSTM两者来预测整个CTU划分结构，以确定是否应该提前终止模式决策[120]。

图像和视频压缩的目标是在保持高质量的前提下，寻求对视觉信号更紧凑的表示，在大数据时代变得越来越重要。本文综述了基于神经网络的图像和视频压缩技术，特别是最近基于深度学习的图像和视频压缩技术。通过本文前面的回顾，很明显，最先进的基于神经网络的端到端图像压缩仍处于初级阶段，其性能优于JPEG2000，但仅与HEVC相当。将神经网络与传统的混合视频编码框架相结合，与最新的视频编码标准HEVC相比，性能有了显著的提高，这说明混合视频编码框架的优势。

神经网络在图像和视频压缩方面的优势有三个方面。

1. 首先，神经网络良好的内容自适应性优于基于信号处理的模型，因为网络参数是根据大量的实际数据推导出来的，而最新的编码标准中的模型是基于图像和视频的先验知识手工创建的。
2. 其次，神经网络模型广泛采用较大的感受野，不仅可以利用邻近信息，而且可以利用远距离样本来提高编码效率，但传统的编码工具只利用邻近样本，难以利用远距离样本。
3. 第三，神经网络能够很好地表达纹理和特征，使得联合压缩优化兼顾了人眼视觉和机器视觉分析。然而，现有的编码标准只针对人类视觉任务追求高压缩性能。

基于深度学习的图像/视频压缩将在以更好的质量和更少的码率表示和传输图像和视频方面发挥更重要的作用，但仍需要进一步研究以下面临问题：

1. **面向语义保真的图像和视频压缩**。随着计算机视觉技术的快速发展和图像和视频的爆炸性增长，视觉信号接收器不仅可以是人类的视觉系统，而且可以是计算机视觉算法。同时，神经网络在图像和视频理解任务中展现出了巨大优势，神经网络尤其是深度学习技术更适合于语义信息的表示。因此，语义逼真度在满足传统视觉逼真度要求的同时，也将成为进一步应用的关键。
2. **率失真(RD)优化引导神经网络训练和压缩任务的自适应切换**。率失真理论是传统图像和视频压缩成功的关键，但在目前基于神经网络的压缩任务中却没有得到很好的探索。一个单一的网络来处理所有结构各异的图像和视频显然效率低下。因此，多网络根据率失真进行自适应训练和切换是一种可能的解决方案。
3. **实用图像和视频编解码器的高效存储和高效计算设计**。阻碍基于深度学习的图像和视频压缩部署的最大障碍是计算和存储负担。为了获得更高的性能，研究人员通常考虑具有更多网络层和节点的更大的神经网络，但对网络参数的各种效率没有很好的思考。对于图像和视频的压缩问题，目前还没有从神经网络的压缩性能和高效计算、存储两方面综合考虑的相关研究工作，这对于实际应用具有重要意义。

对于面向语义友好的图像和视频压缩，我们尝试设计创新的视觉信号表示框架，以优雅地支持人类视觉观察和机器视觉分析。鉴于特征对于视觉语义描述符(如CNN特征)的轻量级和重要性，我们在文献[121]中提出了将特征描述符和视觉内容联合压缩的分层视觉信号表示方法。更具体地说，对于每个视频帧，首先提取和压缩特征描述符，然后利用解码后的特征通过处理大规模全局运动来辅助视觉内容压缩。该策略不仅提高了视觉内容的压缩效率，而且由于从原始视频中提取特征而不受压缩伪影的影响，保证了视觉分析的性能。在[122]中，我们进一步研究了一种新颖的基于深度学习的端到端图像压缩框架的视觉信号表示结构，它可以直接从压缩域执行更多的图像理解任务。这种方法背后的基本原理在于，通常用于学习压缩的神经网络结构(特别是编码器)与通常用于推理的神经网络结构相似，因此，学习图像编码器原则上能够提取与推理任务相关的特征。因此，这种方法将来可以扩展为同时训练和学习端到端的图像压缩和理解。

在基于CNN的图像和视频压缩中，CNN模型压缩也是一个多变量的优化问题，必须综合考虑计算成本、CNN性能和CNN模型传输速率(如果需要)进行优化。前人的工作[123]针对视频编码问题提出了一种功率约束下的复杂度-失真优化公式，并结合计算代价和视频压缩性能将其进一步扩展到CNN模型的压缩优化。

基于本文的讨论，神经网络在未来的图像和视频压缩任务中也显示出了良好的效果。虽然在计算复杂度和内存消耗方面还存在很多问题，但其对图像和视频信号的高效预测和紧凑表示使得神经网络在现有视频编码框架的基础上获得了可观的编码增益。它们固有的并行友好特性也使其适用于大规模部署的并行计算体系结构，如GPU和TPU。此外，基于网络的端到端优化方法比手工方法更灵活，可以快速优化或调整，这也使得网络在进一步的图像和视频压缩问题以及其他人工智能问题中具有巨大的潜力。

## 预期成果

### 图像压缩

深度学习框架实现图像压缩，在满足压缩率大于20的情况下，实现实时图像压缩。
